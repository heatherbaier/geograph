{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd06e6e7e11ff29b7ea88d93fdd1bf54ac8bd20e793b837d22d51eef8412ed09bee",
   "display_name": "Python 3.7.10 64-bit ('caoe': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hbaier/anaconda3/envs/caoe/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import landsat_prep as lp\n",
    "import geograph as gg\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "ISO = \"MEX\"\n",
    "ADM_ID = \"MEX-ADM2-1590546715-B7\"\n",
    "IC = \"LANDSAT/LT05/C01/T1\"\n",
    "YEAR = \"2010\"\n",
    "MONTH = \"1\"\n",
    "GB_PATH = \"./data/MEX/ipumns_shp.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lp.downloadGB(iso = \"MEX\", \n",
    "#               adm = \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADM_ID = \"484001001\"\n",
    "# lp.prep_landsat(GB_PATH, ISO, ADM_ID, \"2010\", \"1\", IC, v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADM_ID = \"484001003\"\n",
    "lp.prep_landsat(GB_PATH, ISO, ADM_ID, \"2010\", \"1\", IC, v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADM_ID = \"484014116\"\n",
    "lp.prep_landsat(GB_PATH, ISO, ADM_ID, \"2010\", \"1\", IC, v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADM_ID = \"484014046\"\n",
    "lp.prep_landsat(GB_PATH, ISO, ADM_ID, \"2010\", \"1\", IC, v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADM_ID = \"MEX-ADM2-1590546715-B615\"\n",
    "# lp.prep_landsat(GB_PATH, ISO, ADM_ID, \"2010\", \"1\", IC, v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLoader():\n",
    "\n",
    "    class Dataset():\n",
    "        def __init__(self, x, edge_index, batch):\n",
    "            self.x = x\n",
    "            self.edge_index = edge_index\n",
    "            self.batch = batch\n",
    "\n",
    "    def __init__(self, data_dir, iso, batch_size):\n",
    "\n",
    "        self.iso = iso\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.munis = [i for i in os.listdir(self.data_dir) if i != self.iso]\n",
    "        self.image_graphs = [gg.ImageGraph(i) for i in self.munis] \n",
    "        self.indexes = [i for i in range(0, len(self.munis))]\n",
    "        random.shuffle(self.indexes)\n",
    "        self.indexes = [self.indexes[i:i + self.batch_size] for i in range(0, len(self.indexes), self.batch_size)]\n",
    "\n",
    "        self.data = []\n",
    "        [self.data.append(self.load_graph(np.array(self.image_graphs)[batch])) for batch in self.indexes]\n",
    "\n",
    "\n",
    "    def load_graph(self, batch):\n",
    "\n",
    "        # X's \n",
    "        xs = torch.cat([i.x for i in batch])\n",
    "\n",
    "        # Batch ID's\n",
    "        batch_ids = []\n",
    "        node_nums = [i.num_nodes for i in batch]\n",
    "        for i in range(len(node_nums)):\n",
    "            batch_ids.append(np.array([i for n in range(node_nums[i])], dtype = np.float32))        \n",
    "        batch_ids = torch.tensor(np.concatenate(batch_ids))\n",
    "\n",
    "        # Edge Indices\n",
    "        all_edge_indices = []\n",
    "        edge_indices = [i.edge_list for i in batch]\n",
    "        for i in range(len(edge_indices)):\n",
    "            all_edge_indices.append(np.array(edge_indices[i]) + np.sum(np.array(node_nums)[:i]))\n",
    "        edge_indices = torch.tensor(np.concatenate(all_edge_indices))\n",
    "        \n",
    "        return self.Dataset(xs, edge_indices, batch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GraphLoader(\"./data/\", \"MEX\", 4).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher.py [-h] test\nipykernel_launcher.py: error: the following arguments are required: test\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import zipfile\n",
    "import shapely\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from rasterio import plot\n",
    "from rasterio.plot import show\n",
    "\n",
    "\n",
    "class ImageGraph():\n",
    "\n",
    "    def __init__(self, adm_id, dta = None):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - target_id: If loading data for a municiaplity shapefile, should be the \n",
    "              unique shapeID of a municipality, otherwise use 'search' to find the central \n",
    "              most node in a shapefile (use this when you load in the imagery boxes)\n",
    "            - gdf: dataframe with geometry and x & y data IF load_data == True\n",
    "            - degrees: number of degrees away fromt he target municiaplity to contruct the graph\n",
    "        __init__ variables:\n",
    "            - degree_dict: dictionary with keys 0...self.degrees with the values being the list of \n",
    "              shapeID's that are k degrees from the target\n",
    "            - neighbors: dictionary with the keys being each of the municiaplites within self.degrees\n",
    "              from the target and the values being that municiaplites neighbors (that are no further th)\n",
    "        \"\"\"\n",
    "\n",
    "        self.adm_id = adm_id \n",
    "        self.target_path = os.path.join(\"./data/\", adm_id)\n",
    "        self.imagery_dir = os.path.join(self.target_path, \"pngs\")\n",
    "        self.zip_path = os.path.join(self.target_path, \"imagery\")\n",
    "        self.temp_path = os.path.join(self.target_path, \"temp\")\n",
    "        self.shp_path = os.path.join(self.target_path, [i for i in os.listdir(self.target_path) if i.endswith(\".shp\")][0])\n",
    "        self.gdf = gpd.read_file(self.shp_path)\n",
    "        self.degree_dict = {}\n",
    "        self.target_id = 0\n",
    "        self.degrees = 100\n",
    "        \n",
    "\n",
    "        self.x = self.__load_imagery()\n",
    "        self.neighbors = self.__get_spatial_neighbors()\n",
    "        self.edge_list = self.__make_edge_list()\n",
    "        self.adj_list = self.__make_adj_list()\n",
    "        self.adj_matrix = self.__make_adj_matrix()\n",
    "        self.num_nodes = len(self.neighbors.keys())\n",
    "\n",
    "        if dta is not None:\n",
    "            self.dta_path = dta\n",
    "            self.y = self.__get_y()\n",
    "\n",
    "\n",
    "    def __load_image(self, image_path):\n",
    "        image_path = os.path.join(self.imagery_dir, image_path)\n",
    "        to_tens = transforms.ToTensor()\n",
    "        return to_tens(Image.open(image_path).convert('RGB')).unsqueeze(0)\n",
    "\n",
    "    def __load_imagery(self):\n",
    "        images = os.listdir(self.imagery_dir)\n",
    "        images = torch.cat([self.__load_image(i) for i in list(images)], dim = 0)\n",
    "        return images\n",
    "\n",
    "    def __get_spatial_neighbors(self):\n",
    "        \"\"\"\n",
    "        - Returns a dictionary with the keys being the shapeID's of the municipalities in the graph \n",
    "          (within self.degrees) and the values being the neighbors of the shapeID key\n",
    "        - Runs on initialization\n",
    "        \"\"\"\n",
    "        row = self.gdf[self.gdf['shapeID'] == self.target_id].squeeze()\n",
    "        target_neighbors = self.gdf[~self.gdf.geometry.disjoint(row.geometry)].shapeID.tolist()\n",
    "        neighbors = target_neighbors\n",
    "\n",
    "        all_neighbors = {}\n",
    "        self.degree_dict[0] = [self.target_id]\n",
    "        self.degree_dict[1] = [i for i in target_neighbors if i != self.target_id]\n",
    "    \n",
    "        # Get neighbors\n",
    "        for i in range(self.degrees):\n",
    "            new_n = []\n",
    "            for n in neighbors:\n",
    "                cur_row = self.gdf[self.gdf['shapeID'] == n].squeeze()\n",
    "                cur_neighbors = self.gdf[~self.gdf.geometry.disjoint(cur_row.geometry)].shapeID.tolist()\n",
    "                if n not in all_neighbors.keys():\n",
    "                    all_neighbors[n] = cur_neighbors\n",
    "                    new_n.append(n)\n",
    "            if i != 0:\n",
    "                self.degree_dict[i + 1] = new_n\n",
    "\n",
    "            k = [v for k,v in all_neighbors.items()]\n",
    "            k = list(set([item for sublist in k for item in sublist]))\n",
    "            k = [i for i in k if i not in all_neighbors.keys()]\n",
    "            neighbors = k\n",
    "\n",
    "            if len(neighbors) == 0:\n",
    "                break\n",
    "\n",
    "        # Cleanup: remove all ofthe neighbors of neighbors that are more than one degree fromt he target node\n",
    "        # i.i. remove all of the muiciaplites in the values that are not in the keys\n",
    "        u_vals = list(set([item for sublist in all_neighbors.values() for item in sublist]))\n",
    "        remove_vals = [i for i in u_vals if i not in all_neighbors.keys()]\n",
    "        for k,v in all_neighbors.items():\n",
    "            to_remove = [j for j in v if j in remove_vals]\n",
    "            for tr in to_remove:\n",
    "                all_neighbors[k] = [i for i in all_neighbors[k] if i not in tr]\n",
    "\n",
    "        return all_neighbors\n",
    "\n",
    "    def __make_edge_list(self):\n",
    "        edge_list = []\n",
    "        for k,v in self.neighbors.items():\n",
    "            [edge_list.append([k, cur_v]) for cur_v in v]\n",
    "        return edge_list\n",
    "\n",
    "    def __make_adj_list(self):\n",
    "        \"\"\"\n",
    "        Returns an adjacency list based on the self.neighbors_recoded dictionary.\n",
    "        Since every element in the array needs to have the same number of values, but muni's don't all \n",
    "        have the same number of neighbors, it fills the remaining elements in each list with the value -99.\n",
    "        \"\"\"\n",
    "        max_n = len(self.neighbors.keys())\n",
    "        adj_list = np.full((max_n, max_n), -99)\n",
    "        for i in self.neighbors.values():\n",
    "            cur_new_vals = np.pad(np.array(i), (0, max_n - len(i)), constant_values = -99)\n",
    "            try:\n",
    "                new_values = np.concatenate((new_values, cur_new_vals))\n",
    "            except Exception as e:\n",
    "                new_values = cur_new_vals\n",
    "        return np.reshape(new_values, (max_n, max_n))\n",
    "\n",
    "    def __make_adj_matrix(self):\n",
    "        adj_matrix = np.zeros((len(self.gdf), len(self.gdf)))\n",
    "        for edge in self.edge_list:\n",
    "            adj_matrix[edge[0]][edge[1]] = 1\n",
    "        for i in range(len(self.gdf)):\n",
    "            adj_matrix[i][i] = 1\n",
    "        return adj_matrix\n",
    "\n",
    "    \n",
    "    def __get_y(self):\n",
    "\n",
    "        m = open(self.dta_path,)\n",
    "        data = json.load(m)\n",
    "        m.close()\n",
    "\n",
    "        return data[self.adm_id]\n",
    "\n",
    "\n",
    "    def show(self):\n",
    "\n",
    "        try:\n",
    "            os.mkdir(self.temp_path)\n",
    "        except:\n",
    "            shutil.rmtree(self.temp_path)\n",
    "        \n",
    "        for zipfolder in os.listdir(self.zip_path):\n",
    "            with zipfile.ZipFile(os.path.join(self.zip_path, zipfolder), 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.temp_path)\n",
    "\n",
    "        b1s = [i for i in os.listdir(self.temp_path) if i.endswith(\"B1.tif\")]\n",
    "        b1s = [rio.open(os.path.join(self.temp_path, i)) for i in b1s]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize = (12, 10))\n",
    "        for i in b1s:\n",
    "            show(i, ax = ax, transform = i.transform, cmap = 'gist_earth')\n",
    "        self.gdf.plot(ax = ax, color = 'black', alpha = 0) ## alpha is the transparency setting\n",
    "        # plt.show()\n",
    "\n",
    "        shutil.rmtree(self.temp_path)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"test\", help=\"Path to exported Mexico ADM2 shapefile\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.test == 'random':\n",
    "\n",
    "        adms = [i for i in os.listdir(\"./data/\") if \"-B\" in i]\n",
    "        print(\"ADM's available: \", adms)\n",
    "        index = random.randint(0, len(adms) - 1)\n",
    "        adm_id = adms[index]\n",
    "\n",
    "        print(\"Selected ADM: \", adm_id)\n",
    "\n",
    "        ig = ImageGraph(adm_id = adm_id)\n",
    "        ig.show()\n",
    "        plt.savefig(\"./test.png\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        import landsat_prep as lp\n",
    "\n",
    "        GB_PATH = \"./data/MEX/MEX_ADM2_fixedInternalTopology.shp\"\n",
    "        ADM_ID = args.test\n",
    "        ISO = \"MEX\"\n",
    "        IC = \"LANDSAT/LT05/C01/T1\"\n",
    "\n",
    "        lp.prep_landsat(GB_PATH, ISO, ADM_ID, \"2010\", \"1\", IC)\n",
    "\n",
    "        ig = ImageGraph(adm_id = ADM_ID)\n",
    "        ig.show()\n",
    "        plt.savefig(\"./test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"./data/MEX/geo2_mx1960_2015.shp\")\n",
    "gdf = gdf[[\"GEOLEVEL2\", \"geometry\"]]\n",
    "gdf.columns = [\"shapeID\", \"geometry\"]\n",
    "gdf.to_file(\"./ipumns_shp.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}