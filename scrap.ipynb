{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('qnn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4978dc1864a661fcd348fb688fbace178c7388184fc0914a9258717a7a8394e1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "\"\"\"\n",
    "    1) Each node v ∈ V aggregates the representations of the nodes in its immediate neighborhood, into a single vector (Note that this aggregation\n",
    "step depends on the representations generated at the previous iteration of the outer loop and the k = 0 (“base case”) representations are defined as the input node features)\n",
    "    2) After aggregating\n",
    "the neighboring feature vectors, GraphSAGE then concatenates the node’s current representation with the aggregated neighborhood vector ... torch.cat((node_features, neighbor_features), dim = 1)\n",
    "    3) This concatenated vector is fed through a fully connected layer with nonlinear activation function σ, which transforms the representations to be used at the next step of the algorithm\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n    1) Each node v ∈ V aggregates the representations of the nodes in its immediate neighborhood, into a single vector (Note that this aggregation\\nstep depends on the representations generated at the previous iteration of the outer loop and the k = 0 (“base case”) representations are defined as the input node features)\\n    2) After aggregating\\nthe neighboring feature vectors, GraphSAGE then concatenates the node’s current representation with the aggregated neighborhood vector ... torch.cat((node_features, neighbor_features), dim = 1)\\n    3) This concatenated vector is fed through a fully connected layer with nonlinear activation function σ, which transforms the representations to be used at the next step of the algorithm\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.9714, 0.9065],\n",
       "        [0.6259, 0.3734],\n",
       "        [0.7635, 0.8703],\n",
       "        [0.1528, 0.7398],\n",
       "        [0.6117, 0.7816]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "x = torch.rand(5,2, requires_grad = True, dtype = torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3, -99],\n",
       "        [  0,   2,   3, -99],\n",
       "        [  0,   3,   4, -99],\n",
       "        [  0,   1,   2,   4],\n",
       "        [  2,   3, -99, -99]])"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "adj_list = torch.tensor(\n",
    "                        [[1,2,3,-99],\n",
    "                         [0,2,3,-99],\n",
    "                         [0,3,4,-99],\n",
    "                         [0,1,2,4],\n",
    "                         [2,3,-99,-99]]\n",
    "                         \n",
    "                         )\n",
    "adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_degree_hotter(adj_list):\n",
    "\n",
    "    new_adj_list = torch.ones(adj_list.shape[0], torch.max(adj_list) * torch.max(adj_list))\n",
    "\n",
    "    for i in range(0, adj_list.shape[0]): \n",
    "        cur_nodes = adj_list[i]\n",
    "        cur_stack = torch.tensor([-99]) \n",
    "        for j in cur_nodes:\n",
    "            if j != -99:\n",
    "                nodes_to_add_in = adj_list[j]\n",
    "                for n in nodes_to_add_in:\n",
    "                    if n not in cur_stack and n not in cur_nodes and n != i:\n",
    "                        cur_stack = torch.cat((cur_stack, n.unsqueeze(0)))\n",
    "        ready_to_stack = torch.nn.functional.pad(cur_stack, (0, adj_list.shape[0] - cur_stack.shape[0]), value = -99).unsqueeze(0)\n",
    "        try:\n",
    "            final_stack = torch.cat((final_stack, ready_to_stack), dim = 0)\n",
    "        except:\n",
    "            final_stack = ready_to_stack\n",
    "\n",
    "    return final_stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-99,   4, -99, -99, -99],\n",
       "        [-99,   4, -99, -99, -99],\n",
       "        [-99,   1, -99, -99, -99],\n",
       "        [-99, -99, -99, -99, -99],\n",
       "        [-99,   0,   1, -99, -99]])"
      ]
     },
     "metadata": {},
     "execution_count": 234
    }
   ],
   "source": [
    "test = one_degree_hotter(adj_list)\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-99,   1, -99, -99, -99],\n",
       "        [-99,   0, -99, -99, -99],\n",
       "        [-99,   4, -99, -99, -99],\n",
       "        [-99, -99, -99, -99, -99],\n",
       "        [-99, -99, -99, -99, -99]])"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "source": [
    "test2 = one_degree_hotter(test)\n",
    "test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1)\ntensor(2)\ntensor(3)\ntensor(-99)\ntensor(0)\ntensor(2)\ntensor(3)\ntensor(-99)\ntensor(0)\ntensor(3)\ntensor(4)\ntensor(-99)\ntensor(0)\ntensor(1)\ntensor(2)\ntensor(4)\ntensor(2)\ntensor(3)\ntensor(-99)\ntensor(-99)\n"
     ]
    }
   ],
   "source": [
    "for i in adj_list:\n",
    "    for j in i:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sage(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, feature_dim, num_classes, K): \n",
    "        super(Sage, self).__init__()\n",
    "        '''weights is of shape [embed_dim (arbitrary), feature_dim * 2]'''\n",
    "        self.w1 = torch.nn.Parameter(torch.rand(embed_dim, feature_dim * 2), requires_grad = True)\n",
    "        self.w2 = torch.nn.Parameter(torch.rand(num_classes, embed_dim), requires_grad = True)\n",
    "        self.K = K\n",
    "\n",
    "\n",
    "    def forward(self, x, adj_list):\n",
    "\n",
    "        # for degree in range(self.K):\n",
    "        \n",
    "        #     if degree == 1:\n",
    "\n",
    "        #         adj_list = adj_list\n",
    "            \n",
    "        #     else:\n",
    "\n",
    "        #         adj_list = one_degree_hotter(adj_list)\n",
    "\n",
    "        for node in adj_list:\n",
    "            cur_neigh_feats = torch.mean(torch.index_select(x, 0, node[node > 0]), dim = 0).unsqueeze(0)\n",
    "            try:\n",
    "                neigh_feats = torch.cat((neigh_feats, cur_neigh_feats), dim = 0)\n",
    "            except:\n",
    "                neigh_feats = cur_neigh_feats\n",
    "\n",
    "        combined = torch.cat((x, neigh_feats), dim = 1)\n",
    "        combined = torch.mm(self.w1, combined.t())\n",
    "        out = torch.mm(self.w2, combined).t()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sage_net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, feature_dim, num_classes, K): \n",
    "        super(sage_net, self).__init__()\n",
    "        self.s = Sage(embed_dim, feature_dim, num_classes, K)\n",
    "        # self.fc = torch.nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x, adj_list = x[0], x[1]\n",
    "\n",
    "        out = self.s(x, adj_list)\n",
    "        out = torch.mean(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([[3, 3, 0, 3, 1, 3, 2],\n",
    "#         [3, 0, 3, 1, 3, 2, 3]]).t()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1.0000, 1.0000, 0.0396, 0.9787],\n",
    "        [0.5366, 0.5700, 0.1209, 0.5313],\n",
    "        [0.2313, 0.2818, 0.1446, 0.4948],\n",
    "        [0.2336, 0.0585, 0.2096, 0.8928]], dtype = torch.float32, requires_grad = True)\n",
    "y = torch.tensor([345.], dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "adj_list = torch.tensor([[1,3,-99],\n",
    "            [0,2,3],\n",
    "            [1,3,-99],\n",
    "            [0,1,2]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "108985.1953125\n",
      "104965.4609375\n",
      "100576.9375\n",
      "95755.4609375\n",
      "90493.078125\n",
      "84802.515625\n",
      "78709.9765625\n",
      "72253.6171875\n",
      "65483.82421875\n",
      "58464.1796875\n",
      "51272.62890625\n",
      "44002.859375\n",
      "36765.76953125\n",
      "29690.908203125\n",
      "22927.86328125\n",
      "16647.52734375\n",
      "11043.125\n",
      "6330.82275390625\n",
      "2749.729736328125\n",
      "560.896728515625\n",
      "44.884437561035156\n",
      "1497.08154296875\n",
      "5219.64794921875\n",
      "11508.3369140625\n",
      "20631.5078125\n",
      "32797.37890625\n",
      "48103.99609375\n",
      "66464.734375\n",
      "87503.1953125\n",
      "110420.15625\n",
      "133863.046875\n",
      "155882.59375\n",
      "174108.5625\n",
      "186224.4375\n",
      "190602.4375\n",
      "186776.28125\n",
      "175489.609375\n",
      "158354.84375\n",
      "137368.5\n",
      "114507.71875\n",
      "91492.5859375\n",
      "69690.75\n",
      "50108.265625\n",
      "33423.22265625\n",
      "20033.669921875\n",
      "10107.7841796875\n",
      "3630.128662109375\n",
      "442.8656311035156\n",
      "281.5325012207031\n",
      "2805.91162109375\n",
      "7626.43603515625\n",
      "14326.6064453125\n",
      "22481.70703125\n",
      "31674.201171875\n",
      "41505.94140625\n",
      "51607.4765625\n",
      "61644.75390625\n",
      "71323.375\n",
      "80390.8515625\n",
      "88636.90625\n",
      "95892.625\n",
      "102028.09375\n",
      "106949.640625\n",
      "110596.2734375\n",
      "112936.140625\n",
      "113962.8203125\n",
      "113692.078125\n",
      "112158.6796875\n",
      "109414.09375\n",
      "105524.515625\n",
      "100569.640625\n",
      "94642.0\n",
      "87847.078125\n",
      "80303.8125\n",
      "72145.8515625\n",
      "63523.01953125\n",
      "54603.29296875\n",
      "45575.0\n",
      "36648.97265625\n",
      "28060.7578125\n",
      "20072.501953125\n",
      "12974.4326171875\n",
      "7085.572265625\n",
      "2753.584716796875\n",
      "353.3282470703125\n",
      "283.8825988769531\n",
      "2963.62744140625\n",
      "8822.9814453125\n",
      "18294.38671875\n",
      "31799.0703125\n",
      "49729.87109375\n",
      "72430.0078125\n",
      "100166.7265625\n",
      "133100.3125\n",
      "171247.25\n",
      "214438.859375\n",
      "262275.78125\n",
      "314081.78125\n",
      "368859.09375\n",
      "425253.65625\n",
      "481538.90625\n",
      "535631.0\n",
      "585149.1875\n",
      "627535.5\n",
      "660238.75\n",
      "680958.0\n",
      "687916.375\n",
      "680117.75\n",
      "657528.5625\n",
      "621140.25\n",
      "572881.1875\n",
      "515406.21875\n",
      "451804.03125\n",
      "385286.90625\n",
      "318912.03125\n",
      "255370.828125\n",
      "196854.3125\n",
      "144992.078125\n",
      "100849.8984375\n",
      "64968.98046875\n",
      "37431.71484375\n",
      "17941.240234375\n",
      "5903.97216796875\n",
      "510.3672180175781\n",
      "808.4779052734375\n",
      "5768.68701171875\n",
      "14338.275390625\n",
      "25485.771484375\n",
      "38235.51953125\n",
      "51693.23046875\n",
      "65063.63671875\n",
      "77661.28125\n",
      "88915.7109375\n",
      "98372.359375\n",
      "105689.875\n",
      "110635.3125\n",
      "113077.7109375\n",
      "112981.0859375\n",
      "110397.1015625\n",
      "105458.359375\n",
      "98372.03125\n",
      "89414.6171875\n",
      "78927.5078125\n",
      "67313.640625\n",
      "55034.95703125\n",
      "42610.41796875\n",
      "30614.810546875\n",
      "19677.42578125\n",
      "10480.734375\n",
      "3758.466796875\n",
      "292.76934814453125\n",
      "909.8780517578125\n",
      "6473.93798828125\n",
      "17878.37890625\n",
      "36034.32421875\n",
      "61855.3984375\n",
      "96238.625\n",
      "140040.40625\n",
      "194047.234375\n",
      "258940.90625\n",
      "335257.53125\n",
      "423340.0625\n",
      "523284.46875\n",
      "634881.5625\n",
      "757552.0\n",
      "890282.75\n",
      "1031562.5625\n",
      "1179326.0\n",
      "1330913.75\n",
      "1483056.625\n",
      "1631896.5\n",
      "1773063.625\n",
      "1901811.75\n",
      "2013228.375\n",
      "2102516.75\n",
      "2165334.5\n",
      "2198158.75\n",
      "2198631.5\n",
      "2165832.5\n",
      "2100430.75\n",
      "2004683.375\n",
      "1882279.125\n",
      "1738047.25\n",
      "1577578.875\n",
      "1406817.75\n",
      "1231662.625\n",
      "1057631.0\n",
      "889599.1875\n",
      "731625.875\n",
      "586868.375\n",
      "457560.75\n",
      "345055.9375\n",
      "249904.859375\n",
      "171964.0\n",
      "110514.203125\n",
      "64385.16015625\n",
      "32074.484375\n",
      "11858.4970703125\n",
      "1890.5458984375\n",
      "285.5200500488281\n",
      "tensor(328.1027, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = sage_net(embed_dim = 16, feature_dim = 4, num_classes = 1, K = 2)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "# y = torch.tensor([1,2,3,4,5], dtype = torch.float32, requires_grad = True).view(-1, 1)\n",
    "\n",
    "input = (x, adj_list)\n",
    "\n",
    "for i in range(0, 200):\n",
    "\n",
    "    pred = model(input)\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    print(loss.item())\n",
    "    # print(pred.item())\n",
    "\n",
    "    grad = torch.autograd.grad(outputs = loss, inputs = input[0], retain_graph = True)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.5918, 0.3897],\n        [0.6808, 0.2922],\n        [0.5245, 0.2379],\n        [0.5572, 0.3854],\n        [0.6808, 0.2922]])\n"
     ]
    }
   ],
   "source": [
    "try: del neigh_feats\n",
    "except: pass\n",
    "\n",
    "\n",
    "for node in adj_list:\n",
    "    cur_neigh_feats = torch.mean(torch.index_select(x, 0, node[node > 0]), dim = 0).unsqueeze(0)\n",
    "    try:\n",
    "        neigh_feats = torch.cat((neigh_feats, cur_neigh_feats), dim = 0)\n",
    "    except:\n",
    "        neigh_feats = cur_neigh_feats\n",
    "\n",
    "print(neigh_feats)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.5480, 0.6868],\n",
       "        [0.3765, 0.5615],\n",
       "        [0.1179, 0.6393],\n",
       "        [0.5240, 0.5442],\n",
       "        [0.3765, 0.5615]])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "neigh_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7804, 0.7554],\n",
       "        [0.8911, 0.9375],\n",
       "        [0.5990, 0.2697],\n",
       "        [0.1539, 0.8532],\n",
       "        [0.0819, 0.4254]])"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7804, 0.7554, 0.5480, 0.6868],\n",
       "        [0.8911, 0.9375, 0.3765, 0.5615],\n",
       "        [0.5990, 0.2697, 0.1179, 0.6393],\n",
       "        [0.1539, 0.8532, 0.5240, 0.5442],\n",
       "        [0.0819, 0.4254, 0.3765, 0.5615]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "cat = torch.cat((x, neigh_feats), dim = 1)\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7804, 0.8911, 0.5990, 0.1539, 0.0819],\n",
       "        [0.7554, 0.9375, 0.2697, 0.8532, 0.4254],\n",
       "        [0.5480, 0.3765, 0.1179, 0.5240, 0.3765],\n",
       "        [0.6868, 0.5615, 0.6393, 0.5442, 0.5615]])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "cat.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.3884],\n",
       "        [-0.3401],\n",
       "        [-0.3273],\n",
       "        [-0.1176],\n",
       "        [-0.1519]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "l = torch.nn.Linear(4, 1)\n",
    "l(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7348, 0.4718, 0.1690, 0.1551]])"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "param = torch.rand(1, 4)\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.8810, 0.8597, 0.5320, 0.7657, 0.5579]])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "param.mm(cat.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(128, 2866)\n",
    "t2 = torch.rand(724, 2866)\n",
    "# t3 = torch.rand(1)\n",
    "\n",
    "# torch.cat((t1, t2, t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1119, 0.2839, 0.9802,  ..., 0.1941, 0.5874, 0.9189],\n",
       "        [0.7242, 0.6031, 0.9000,  ..., 0.2070, 0.0143, 0.3608],\n",
       "        [0.2858, 0.7533, 0.4856,  ..., 0.2480, 0.1502, 0.6680],\n",
       "        ...,\n",
       "        [0.5362, 0.1371, 0.0212,  ..., 0.9871, 0.5192, 0.6612],\n",
       "        [0.3483, 0.7225, 0.5843,  ..., 0.5180, 0.6524, 0.9938],\n",
       "        [0.5438, 0.2904, 0.3011,  ..., 0.1303, 0.5327, 0.6136]])"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0219, 0.1333]])"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "param = torch.rand(1, 2)\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 724])"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "t1.mm(t2.t()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adjacency List:\n0 -> 2\n1 -> 2\n2 -> 0 -> 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# converts from adjacency matrix to adjacency list\n",
    "def convert(a):\n",
    "    adjList = defaultdict(list)\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a[i])):\n",
    "                       if a[i][j]== 1:\n",
    "                           adjList[i].append(j)\n",
    "    return adjList\n",
    "  \n",
    "# driver code\n",
    "a =[[0, 0, 1], [0, 0, 1], [1, 1, 0]] # adjacency matrix\n",
    "AdjList = convert(a)\n",
    "print(\"Adjacency List:\")\n",
    "# print the adjacency list\n",
    "for i in AdjList:\n",
    "    print(i, end =\"\")\n",
    "    for j in AdjList[i]:\n",
    "        print(\" -> {}\".format(j), end =\"\")\n",
    "    print()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}